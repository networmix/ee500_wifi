{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install the required packages\n",
    "!pip3 install numpy pandas matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_PATH = \"./data.db\"  # Path to the database file (relative to the current directory)\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "con = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Read data from the database into\n",
    "df_exp = pd.read_sql_query(\"SELECT * from Experiments\", con)\n",
    "df_meta = pd.read_sql_query(\"SELECT * from Metadata\", con)\n",
    "df_data = pd.read_sql_query(\"SELECT * from Singletons\", con)\n",
    "\n",
    "# Close the connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually peek at the data if needed\n",
    "df_exp.head()\n",
    "# df_meta.head()\n",
    "# df_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of the key performance metrics we will collect in our model:\n",
    "* Application\n",
    "  1. Offered Load (APP_TX_Rate) - measures how much data is sent by the Sender Application over a certain period of time.\n",
    "  1. Throughput (APP_RX_Rate) - measures how much data is successfully delivered over a certain period of time between the Sender and Receiver applications. \n",
    "  1. Loss Ratio (APP_Loss_Ratio) – measures the ratio of lost datagrams to the total number of datagrams emitted by the sender. A lower value is better as it indicates fewer datagrams were lost and thus a more reliable connection. If this value is zero, then there was no loss at the application level.\n",
    "  1. Delay (APP_Delay) - measures the time delay for a piece of data to travel from the Sender to the Receiver. When a datagram is sent by the Sender Application, it is tagged with the current time. If the packet is transmitted and received successfully, the Receiver Application calculates the time difference between the current time and the timestamp embedded in the packet. This difference is the end-to-end data delay (also can be referred as latency).\n",
    "* WiFi MAC\n",
    "  1. MAC Data TX Rate (MAC_TX_Rate) – measures how much data is sent by the sender’s MAC layer over a certain period of time. \n",
    "  1. MAC Data RX Rate (MAC_RX_Rate) – measures how much data is successfully received by the receiver’s MAC layer over a certain period of time.\n",
    "  1. MAC Loss Ratio (MAC_Loss_Ratio) – measures the ratio of packets lost in transmission to the total number of packets enqueued into the MAC layer on the sender’s side. A lower value is better as it indicates fewer IP packets were lost after being admitted into the MAC layer and thus a more reliable connection. If this value is zero, then there was no loss at the MAC level.\n",
    "* WiFi PHY\n",
    "  1. PHY Data TX Rate (PHY_TX_Rate) – measures how much data is sent by the sender’s PHY layer over a certain period of time. Only unicast data MPDUs are taken into consideration.\n",
    "  1. PHY Data RX Rate (PHY_RX_Rate) – measures how much data is successfully received by the receiver’s PHY layer over a certain period of time. Only unicast data MPDUs are taken into consideration.\n",
    "  1. PHY Loss Ratio (PHY_Loss_Ratio) – measures the ratio of unicast data MPDUs lost in transmission to the total number of unicast data MPDUs enqueued into the PHY layer on the sender’s side. A lower value is better as it indicates fewer MPDUs were lost in transit and required retransmission. If this value is zero, then there was no loss at the physical level.\n",
    "  1. PHY Average RSSI (PHY_AVG_RSSI) – measures the average received signal strength indicator (RSSI) of all the received unicast data MPDUs. A higher value is better as it indicates a stronger signal strength. The RSSI is measured in dBm.\n",
    "\n",
    "Note: Application metrics are collected for each AP-STA pair, while MAC and PHY metrics are collected across all STAs in aggregate.\n",
    "\n",
    "Payload size presented to MAC layer is APP_SIZE + UDP_HEADER_SIZE + IP_HEADER_SIZE:\n",
    "macPayloadSize = packetSize + 8 + 20;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "\n",
    "# Step 1: Parse `name` to extract `node_id` and `run`\n",
    "df_data['node_id'] = df_data['name'].str.extract(r'(node\\[\\d+\\])', expand=False)\n",
    "df_data['node_id'].fillna('aggregate', inplace=True)  # Assign 'aggregate' to the rows that are not related to any specific node\n",
    "\n",
    "# Step 2: Pivot the DataFrames\n",
    "df_data_pivot = df_data.pivot_table(index=['run', 'node_id'], columns='variable', values='value')\n",
    "df_data_pivot.reset_index(inplace=True)  # Reset the index to make `run` and `node_id` as columns\n",
    "\n",
    "df_meta_pivot = df_meta.pivot(index='run', columns='key', values='value')\n",
    "df_meta_pivot = df_meta_pivot.apply(pd.to_numeric, errors='ignore')  # Convert all values to numeric where possible\n",
    "df_meta_pivot.reset_index(inplace=True)  # Reset the index to make `run` as a column\n",
    "\n",
    "# Step 3: Merge the metadata (df_meta_pivot) and experiment parameters (df_exp)\n",
    "df_meta_pivot = pd.merge(df_meta_pivot, df_exp, on='run', how='left')\n",
    "\n",
    "# Step 4: Sort by elements of column \"run\"\n",
    "df_meta_pivot['sort_by'] = df_meta_pivot['run'].str.split('-')\n",
    "for index, row in df_meta_pivot.iterrows():\n",
    "    df_meta_pivot.at[index, 'sort_by'] = [int(i) for i in row['sort_by']]\n",
    "df_meta_pivot.sort_values(by=['sort_by'], inplace=True)\n",
    "df_meta_pivot.reset_index(drop=True, inplace=True)\n",
    "df_meta_pivot.drop('sort_by', axis=1, inplace=True)\n",
    "\n",
    "# Step 5: Merge the two DataFrames\n",
    "df_data_per_sta = pd.merge(df_meta_pivot, df_data_pivot, on='run', how='left')\n",
    "\n",
    "# Step 6: Calculate 'delay-average' for aggregate \n",
    "# Calculate the average of 'delay-average' for each 'run' where 'node_id' is 'node[x]'\n",
    "avg_delay_df = df_data_per_sta[df_data_per_sta['node_id'].str.contains('node\\[\\d+\\]')].groupby('run')['delay-average'].mean().reset_index()\n",
    "# Rename the column in avg_delay_df\n",
    "avg_delay_df.rename(columns={'delay-average': 'average_node_delay'}, inplace=True)\n",
    "# Merge this back to the original dataframe df_data_per_sta\n",
    "df_data_per_sta = pd.merge(df_data_per_sta, avg_delay_df, on='run', how='left')\n",
    "# Now, for rows where 'node_id' is 'aggregate', replace 'delay-average' with 'average_node_delay'\n",
    "df_data_per_sta.loc[df_data_per_sta['node_id'] == 'aggregate', 'delay-average'] = df_data_per_sta['average_node_delay']\n",
    "# We can now drop the 'average_node_delay' column as it has served its purpose\n",
    "df_data_per_sta.drop('average_node_delay', axis=1, inplace=True)\n",
    "\n",
    "# if column \"distances\" exists and not empty (however, they can all be zero, it's valid), then we need to override the distance values in the \"distance\" column.\n",
    "# the first value in the distances is the distance for the first node (node[1]), the second value is the distance for the second node (node[2]), and so on.\n",
    "# if the number of nodes is larger than the number of distances, then the distance fileld should not be replaced for the remaining nodes.\n",
    "# if the number of nodes is smaller than the number of distances, then the remaining distances should be ignored.\n",
    "if 'distances' in df_data_per_sta.columns and not df_data_per_sta['distances'].isnull().all():\n",
    "    # Split the 'distances' column by comma\n",
    "    df_data_per_sta['distances'] = df_data_per_sta['distances'].str.split(',')\n",
    "    # Iterate through the rows and replace the values in 'distance_new' with the values from 'distances'\n",
    "    for index, row in df_data_per_sta.iterrows():\n",
    "        if row['node_id'] == 'aggregate':\n",
    "            continue\n",
    "        else:\n",
    "            # Get the index of the node\n",
    "            node_index = int(row['node_id'].split('[')[1].split(']')[0])\n",
    "            if node_index > len(row['distances']):\n",
    "                continue\n",
    "            else:\n",
    "                df_data_per_sta.at[index, 'distance'] = row['distances'][node_index - 1]\n",
    "\n",
    "# Step 7: Calculate metrics\n",
    "df_data_per_sta['app_tx_rate'] = df_data_per_sta['sender-tx-packets'] * df_data_per_sta['packetSize'] * 8 / df_data_per_sta['duration'] / 1000  # in kbps\n",
    "df_data_per_sta['app_rx_rate'] = df_data_per_sta['receiver-rx-packets'] * df_data_per_sta['packetSize'] * 8 / df_data_per_sta['duration'] / 1000  # in kbps\n",
    "df_data_per_sta['app_loss_ratio'] = (df_data_per_sta['sender-tx-packets'] - df_data_per_sta['receiver-rx-packets']) / df_data_per_sta['sender-tx-packets']\n",
    "df_data_per_sta['app_delay'] = df_data_per_sta['delay-average'] / 1000000  # Convert to ms from ns\n",
    "df_data_per_sta['mac_payload_size'] = df_data_per_sta['packetSize'] + 28  # 20 for IP header, 8 for UDP header\n",
    "df_data_per_sta['mac_tx_rate'] = df_data_per_sta['mac-tx-frames'] * df_data_per_sta['mac_payload_size'] * 8 / df_data_per_sta['duration'] / 1000  # in kbps\n",
    "df_data_per_sta['mac_rx_rate'] = df_data_per_sta['mac-rx-frames'] * df_data_per_sta['mac_payload_size'] * 8 / df_data_per_sta['duration'] / 1000  # in kbps\n",
    "df_data_per_sta['mac_loss_ratio'] = (df_data_per_sta['mac-tx-frames'] - df_data_per_sta['mac-rx-frames']) / df_data_per_sta['mac-tx-frames']\n",
    "df_data_per_sta['phy_tx_rate'] = df_data_per_sta['phy-mpdu-tx-bytes'] * 8 / df_data_per_sta['duration'] / 1000  # in kbps\n",
    "df_data_per_sta['phy_rx_rate'] = df_data_per_sta['phy-mpdu-rx-bytes'] * 8 / df_data_per_sta['duration'] / 1000  # in kbps\n",
    "df_data_per_sta['phy_loss_ratio'] = df_data_per_sta['phy-mpdu-drop-count'] / df_data_per_sta['phy-mpdu-tx-count']\n",
    "df_data_per_sta['phy_rssi_avg'] = df_data_per_sta['phy-mpdu-rx-rss-sum'] / df_data_per_sta['phy-mpdu-rx-count']  # in dBm\n",
    "\n",
    "# Step 8: Calculate average metrics\n",
    "df_data_per_sta['app_tx_rate_avg'] = df_data_per_sta['app_tx_rate'] / df_data_per_sta['staNum']  # in kbps\n",
    "df_data_per_sta['app_rx_rate_avg'] = df_data_per_sta['app_rx_rate'] / df_data_per_sta['staNum']  # in kbps\n",
    "df_data_per_sta['mac_tx_rate_avg'] = df_data_per_sta['mac_tx_rate'] / df_data_per_sta['staNum']  # in kbps\n",
    "df_data_per_sta['mac_rx_rate_avg'] = df_data_per_sta['mac_rx_rate'] / df_data_per_sta['staNum']  # in kbps\n",
    "df_data_per_sta['phy_tx_rate_avg'] = df_data_per_sta['phy_tx_rate'] / df_data_per_sta['staNum']  # in kbps\n",
    "df_data_per_sta['phy_rx_rate_avg'] = df_data_per_sta['phy_rx_rate'] / df_data_per_sta['staNum']  # in kbps\n",
    "\n",
    "style = {\n",
    "    'app_tx_rate': '{:.2f} kbps',\n",
    "    'app_rx_rate': '{:.2f} kbps',\n",
    "    'app_loss_ratio': '{:.2%}',\n",
    "    'app_delay': '{:.2f} ms',\n",
    "    'mac_tx_rate': '{:.2f} kbps',\n",
    "    'mac_rx_rate': '{:.2f} kbps',\n",
    "    'mac_loss_ratio': '{:.2%}',\n",
    "    'phy_tx_rate': '{:.2f} kbps',\n",
    "    'phy_rx_rate': '{:.2f} kbps',\n",
    "    'phy_loss_ratio': '{:.2%}',\n",
    "    'phy_rssi_avg': '{:.2f} dBm',\n",
    "    'app_tx_rate_avg': '{:.2f} kbps',\n",
    "    'app_rx_rate_avg': '{:.2f} kbps',\n",
    "    'mac_tx_rate_avg': '{:.2f} kbps',\n",
    "    'mac_rx_rate_avg': '{:.2f} kbps',\n",
    "    'phy_tx_rate_avg': '{:.2f} kbps',\n",
    "    'phy_rx_rate_avg': '{:.2f} kbps',\n",
    "    'distance': '{:.2f} m'\n",
    "}\n",
    "\n",
    "# Step 9: Save the DataFrame to a CSV file\n",
    "df_data_per_sta.to_csv('./data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the DataFrame with aggregated metrics ('node_id'=='aggregate')\n",
    "# Select metrics columns\n",
    "# app_metrics_columns = ['run', 'input', 'staNum', 'app_tx_rate', 'app_rx_rate', 'app_loss_ratio', 'app_delay']\n",
    "app_metrics_columns = ['run', 'staNum', \"distance\", 'app_tx_rate_avg', 'app_rx_rate_avg', 'app_loss_ratio', 'app_delay']\n",
    "\n",
    "# Select rows where 'node_id' is 'aggregate'\n",
    "df_app_metrics = df_data_per_sta[df_data_per_sta['node_id'] == 'aggregate'][app_metrics_columns]\n",
    "# reset the index\n",
    "df_app_metrics.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# sort by distance and staNum\n",
    "df_app_metrics.sort_values(by=['distance', 'staNum'], inplace=True)\n",
    "\n",
    "# Use df.style to add some nice formatting to the output\n",
    "styled_df_app_metrics = df_app_metrics.style.format(style)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(styled_df_app_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the DataFrame with aggregated metrics ('node_id'=='aggregate')\n",
    "# Select metrics columns\n",
    "# macphy_metrics_columns = ['run', 'input', 'staNum','mac_tx_rate', 'mac_rx_rate', 'mac_loss_ratio', 'phy_tx_rate', 'phy_rx_rate', 'phy_loss_ratio', 'phy_rssi_avg']\n",
    "macphy_metrics_columns = ['run', 'staNum', \"distance\", 'mac_tx_rate_avg', 'mac_rx_rate_avg', 'mac_loss_ratio', 'phy_tx_rate_avg', 'phy_rx_rate_avg', 'phy_loss_ratio', 'phy_rssi_avg']\n",
    "\n",
    "# Select rows where 'node_id' is 'aggregate'\n",
    "df_macphy_metrics = df_data_per_sta[df_data_per_sta['node_id'] == 'aggregate'][macphy_metrics_columns]\n",
    "# reset the index\n",
    "df_macphy_metrics.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# sort by distance and staNum\n",
    "df_macphy_metrics.sort_values(by=['distance', 'staNum'], inplace=True)\n",
    "\n",
    "# Use df.style to add some nice formatting to the output\n",
    "styled_df_macphy_metrics = df_macphy_metrics.style.format(style)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(styled_df_macphy_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the DataFrame with per-user metrics ('node_id'!='aggregate')\n",
    "# Select metrics columns\n",
    "app_metrics_columns = ['run', 'input', 'node_id', 'app_tx_rate', 'app_rx_rate', 'app_loss_ratio', 'app_delay']\n",
    "\n",
    "# Select rows where 'node_id' is 'aggregate'\n",
    "df_app_metrics = df_data_per_sta[df_data_per_sta['node_id'] != 'aggregate'][app_metrics_columns]\n",
    "# reset the index\n",
    "df_app_metrics.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Use df.style to add some nice formatting to the output\n",
    "styled_df_app_metrics = df_app_metrics.style.format(style)\n",
    "\n",
    "# Display the DataFrame\n",
    "# display(styled_df_app_metrics)\n",
    "\n",
    "\n",
    "# Display separate output per run_id of run column\n",
    "# for run_id in df_app_metrics['run'].unique():\n",
    "#     display(df_app_metrics[df_app_metrics['run'] == run_id].style.format(style))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(df, x_var, y_var, plot_type='scatter', x_label=None, y_label=None, title=None, legend=True, hue=None, palette='bright'):\n",
    "    \"\"\"\n",
    "    Plot data from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame.\n",
    "        x_var: Name of the column to use as the x variable in the plot.\n",
    "        y_var: Name of the column to use as the y variable in the plot.\n",
    "        plot_type: Type of plot to generate. Default is 'scatter'.\n",
    "    \"\"\"\n",
    "    # Specify the figure size and resolution\n",
    "    plt.figure(figsize=(5, 3), dpi=150)\n",
    "\n",
    "    # Generate the plot\n",
    "    if plot_type == 'scatter':\n",
    "        ax = sns.scatterplot(data=df, x=x_var, y=y_var, hue=hue, legend=legend, palette=palette)\n",
    "    elif plot_type == 'line':\n",
    "        ax = sns.lineplot(data=df, x=x_var, y=y_var, hue=hue, legend=legend, palette=palette)\n",
    "         # Add dots at each data point\n",
    "        sns.scatterplot(data=df, x=x_var, y=y_var, hue=hue, legend=False, palette=palette)\n",
    "    elif plot_type == 'box':\n",
    "        ax = sns.boxplot(data=df, x=x_var, y=y_var, hue=hue, palette=palette)\n",
    "    elif plot_type == 'kde':\n",
    "        ax = sns.kdeplot(data=df, x=x_var, y=y_var, hue=hue, fill=True, palette=palette)\n",
    "    elif plot_type == 'bar':\n",
    "        ax = sns.barplot(data=df, x=x_var, y=y_var, hue=hue, palette=palette)\n",
    "        legend = False  # bar plots typically don't need a legend\n",
    "        if hue == x_var:\n",
    "            # Get a color map\n",
    "            cmap = sns.color_palette(\"husl\", len(df[x_var].unique()))\n",
    "\n",
    "            # Create a dictionary mapping node_id to color\n",
    "            color_dict = dict(zip(df[x_var].unique(), cmap))\n",
    "\n",
    "            # Make the barplot without hue, but with colors mapped according to the dictionary\n",
    "            ax = sns.barplot(data=df, x=x_var, y=y_var, palette=color_dict)\n",
    "        else:\n",
    "            ax = sns.barplot(data=df, x=x_var, y=y_var, hue=hue, palette=palette)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown plot_type: {plot_type}')\n",
    "\n",
    "    # Add grid\n",
    "    ax.grid(True, zorder=0)\n",
    "\n",
    "    # Set zorder for the plots so they are above the grid\n",
    "    if plot_type in ['scatter', 'line']:\n",
    "        for c in ax.collections:\n",
    "            c.zorder = 10\n",
    "\n",
    "    # Add labels and title\n",
    "    x_label = x_var if x_label is None else x_label\n",
    "    y_label = y_var if y_label is None else y_label\n",
    "    title = f'{y_var} vs {x_var}' if title is None else title\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    \n",
    "    # Remove legend if disabled (using hue creates a legend by default)\n",
    "    if not legend:\n",
    "        plt.legend().remove()\n",
    "    else:\n",
    "        # Move legend to the side of the plot\n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "        \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data(df_data_per_sta, 'staNum', 'app_rx_rate_avg', 'line', x_label=\"Number of STAs\", y_label=\"app_rx_rate_avg (kbps)\", legend=False)\n",
    "plot_data(df_data_per_sta[df_data_per_sta['node_id'] == 'aggregate'], 'distance', 'app_rx_rate_avg', 'line', x_label=\"distance (m)\", y_label=\"app_rx_rate_avg (kbps)\", hue=\"staNum\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data(df_data_per_sta, 'node_id', 'app_loss_ratio', 'bar', x_label=\"node_id\", y_label=\"app_loss_ratio\", legend=False)\n",
    "plot_data(df_data_per_sta[df_data_per_sta['node_id'] == 'aggregate'], 'staNum', 'app_loss_ratio', 'line', x_label=\"Number of STAs\", y_label=\"app_loss_ratio\", legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_data(df_data_per_sta, 'node_id', 'app_delay', 'bar', x_label=\"node_id\", y_label=\"app_delay (ms)\", legend=False)\n",
    "plot_data(df_data_per_sta[df_data_per_sta['node_id'] == 'aggregate'], 'staNum', 'app_delay', 'line', x_label=\"Number of STAs\", y_label=\"app_delay (ms)\", legend=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some Path Loss and RSSI calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "c = 3e8  # Speed of light\n",
    "d = np.arange(1, 101, 1)  # Distance array from 1 to 100 meters\n",
    "\n",
    "# Frequencies\n",
    "freq_24_GHz = 2.4e9\n",
    "freq_515_GHz = 5.15e9\n",
    "\n",
    "# Friis path loss formula calculation\n",
    "PL_24_GHz = 20 * np.log10(freq_24_GHz) + 20 * np.log10(4 * np.pi / c) + 20 * np.log10(d)\n",
    "PL_515_GHz = 20 * np.log10(freq_515_GHz) + 20 * np.log10(4 * np.pi / c) + 20 * np.log10(d)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(5, 3), dpi=150)\n",
    "plt.plot(d, PL_24_GHz, label='2.4 GHz')\n",
    "plt.plot(d, PL_515_GHz, label='5.15 GHz')\n",
    "plt.xlabel('Distance (m)')\n",
    "plt.ylabel('Path Loss (dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.title('Path Loss vs Distance at 2.4 GHz and 5.15 GHz')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "tx_power_dbm_values = [16, 20] # Transmit power in dBm values\n",
    "tx_gain_dbi = 0 # Transmit antenna gain in dBi\n",
    "rx_gain_dbi = 0 # Receive antenna gain in dBi\n",
    "pl_exp = 3.0 # Path loss exponent\n",
    "\n",
    "# Frequencies for 2.4 GHz and 5.15 GHz Wi-Fi\n",
    "frequencies = [2.4e9, 5.15e9]\n",
    "freq_labels = ['2.4 GHz', '5.15 GHz']\n",
    "\n",
    "# Generate distances from 1 to 100 meters\n",
    "distances = np.arange(1, 101, 1)\n",
    "\n",
    "# Create 2 plots with larger figure size and DPI\n",
    "fig, axs = plt.subplots(2, figsize=(5, 5), dpi=150)\n",
    "\n",
    "# Calculate RSS for each distance, frequency and power level\n",
    "for freq, ax, label in zip(frequencies, axs, freq_labels):\n",
    "    for tx_power_dbm in tx_power_dbm_values:\n",
    "        ref_loss = 20 * np.log10(freq) + 20 * np.log10(4 * np.pi / 3e8) # Friis free-space model\n",
    "        path_loss = ref_loss + 10 * pl_exp * np.log10(distances)\n",
    "        rss = tx_power_dbm + tx_gain_dbi + rx_gain_dbi - path_loss\n",
    "        ax.plot(distances, rss, label=f'TX Power {tx_power_dbm} dBm')\n",
    "\n",
    "    ax.axhline(-80, color='r', linestyle='--')  # Add horizontal line at -80 dBm\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel('Distance (m)')\n",
    "    ax.set_ylabel('RSS (dBm)')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
